{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Model, Sequential\n",
    "from keras.layers import (Input, Dense, Embedding, Flatten, Concatenate,\n",
    "                          Dropout, Normalization, StringLookup)\n",
    "from keras.optimizers.legacy import Adam # Metal only supports legacy Adam\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from utils import DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Option 3: Use Embedding of selfies structure\n",
    "\n",
    "We will create an embedding of the \"SELFIE\" tokens using  `tensorflow` [StringLookup](https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup) to encode the selfie tokens into consistent categorical int values, and [Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) to create a the embedding vector for each Chromophore.\n",
    "\n",
    "The `y` dataframe already includes the encoded `selfie` string for each chromophore, but we will need to pad the tokens to a max-length as the Emdedding requires that all the feature vectors be of the same length.\n",
    "\n",
    "We could use the `selfies` module inbuild functions to split the selfies and create a standard vocab or alphabet of tokens that we will see, but they are a little clunky as they return consumable generator objects.  So using simple regular expression to do the same job.\n",
    "\n",
    "We can add extra 'buckets' for 'out-of-vocab' tokens that could be present in molecules not in the training set, and we need to add a special 'mask token' `[nop]` to represent a padded token that should be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to tokenize selfies\n",
    "def split_selfie(selfie):\n",
    "    \"\"\"Split a selfie string into a list of tokens.\"\"\"\n",
    "    tokens = re.findall(r\"(\\[.*?\\])\", selfie)\n",
    "    return tokens\n",
    "\n",
    "def pad_selfie(selfie, pad_length):\n",
    "    \"\"\"Pad a selfie to a standard length and convert to a tensor.\"\"\"\n",
    "    tokens = split_selfie(selfie)\n",
    "    padding = [\"[nop]\"] * (pad_length - len(tokens))\n",
    "    tokens = tokens + padding\n",
    "    return tf.convert_to_tensor(tokens, dtype=tf.string)\n",
    "\n",
    "\n",
    "def pad_selfies_tokens(selfies, pad_length):\n",
    "    \"\"\"Pad a list of tokens to a standard length and convert to a tensor.\"\"\"\n",
    "    selfies_tokens = [pad_selfie(selfie, pad_length) for selfie in selfies]\n",
    "    return tf.convert_to_tensor(selfies_tokens, dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset for this specific notebook\n",
    "def notebook_dataset():\n",
    "    lec_data = DataSet(\n",
    "        target=\"LogExtCoeff\",\n",
    "        fill_na=\"drop\",\n",
    "        drop_na_selfies=True,\n",
    "        descriptors=\"continuous\",\n",
    "        drop_features=['Ipc']\n",
    "    )\n",
    "    return lec_data\n",
    "\n",
    "lec_data = notebook_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 10:52:20.877706: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2023-07-18 10:52:20.877730: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-07-18 10:52:20.877734: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-07-18 10:52:20.877771: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-07-18 10:52:20.877787: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the SELFIES\n",
    "selfie_tokens = [split_selfie(s) for s in lec_data.y[\"SELFIES\"]]\n",
    "\n",
    "# Calculate the maximum length of the SELFIES\n",
    "max_len = max([len(tokens) for tokens in selfie_tokens])\n",
    "print(f\"Max length: {max_len}\")\n",
    "\n",
    "\n",
    "# Create the train and test data\n",
    "y_train = lec_data.y_train[\"LogExtCoeff\"]\n",
    "y_test = lec_data.y_test[\"LogExtCoeff\"]\n",
    "sf_train = pad_selfies_tokens(lec_data.y_train[\"SELFIES\"], max_len)\n",
    "sf_test = pad_selfies_tokens(lec_data.y_test[\"SELFIES\"], max_len)\n",
    "x_train = lec_data.X_train\n",
    "x_test = lec_data.X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The limit of max-length will potentially cause issues if encountering longer molecules in any explored chemical space.  Could set larger - but not certain this will help accurancy as the model would never have been trained on any samples of the extended length.  Unclear to me how a RNN would change this ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of token_vocab: 68\n"
     ]
    }
   ],
   "source": [
    "#### SELFIE MODEL ####\n",
    "# Create a vocabulary of all the SELFIES tokens\n",
    "vocab = list(set([token for tokens in selfie_tokens for token in tokens]))\n",
    "print(f\"Number of token_vocab: {len(vocab)}\")\n",
    "\n",
    "# Create a single-input model with the embedded SELFIES\n",
    "num_oov = 2\n",
    "lookup_params = {\n",
    "    \"vocabulary\": vocab,\n",
    "    \"mask_token\": \"[nop]\",\n",
    "    \"num_oov_indices\": num_oov,\n",
    "    \"name\": \"SELFIES_LOOKUP\",\n",
    "}\n",
    "embed_params = {\n",
    "    \"input_dim\": len(vocab) + num_oov,\n",
    "    \"output_dim\": 32,\n",
    "    \"mask_zero\": True,\n",
    "    \"name\": \"SELFIES_EMBEDDING\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " SELFIES_LOOKUP (StringLook  (None, 283)               0         \n",
      " up)                                                             \n",
      "                                                                 \n",
      " SELFIES_EMBEDDING (Embeddi  (None, 283, 32)           2240      \n",
      " ng)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9056)              0         \n",
      "                                                                 \n",
      " HIDDEN_0 (Dense)            (None, 32)                289824    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " OUTPUT (Dense)              (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 292097 (1.11 MB)\n",
      "Trainable params: 292097 (1.11 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "selfie_model = Sequential(\n",
    "    [\n",
    "        Input(shape=(max_len,), dtype=object, name=\"SELFIES\"),\n",
    "        StringLookup(**lookup_params),\n",
    "        Embedding(**embed_params),\n",
    "        Flatten(),\n",
    "        Dense(32, activation='relu', name=\"HIDDEN_0\"),\n",
    "        # Dropout(0.5),\n",
    "        # Dense(4, activation='relu', name=\"HIDDEN_1\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(1, name=\"OUTPUT\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "selfie_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error',\n",
    ")\n",
    "selfie_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 19:35:03.064988: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 10s 124ms/step - loss: 1.2408 - val_loss: 0.2713\n",
      "Epoch 2/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 19:35:13.174248: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 10s 121ms/step - loss: 0.3304 - val_loss: 0.2171\n",
      "Epoch 3/25\n",
      "81/81 [==============================] - 10s 118ms/step - loss: 0.2869 - val_loss: 0.1941\n",
      "Epoch 4/25\n",
      "81/81 [==============================] - 10s 119ms/step - loss: 0.2512 - val_loss: 0.1673\n",
      "Epoch 5/25\n",
      "81/81 [==============================] - 10s 120ms/step - loss: 0.2261 - val_loss: 0.1588\n",
      "Epoch 6/25\n",
      "81/81 [==============================] - 10s 119ms/step - loss: 0.2124 - val_loss: 0.1529\n",
      "Epoch 7/25\n",
      "81/81 [==============================] - 10s 119ms/step - loss: 0.1955 - val_loss: 0.1494\n",
      "Epoch 8/25\n",
      "81/81 [==============================] - 10s 120ms/step - loss: 0.1844 - val_loss: 0.1673\n",
      "Epoch 9/25\n",
      "81/81 [==============================] - 10s 120ms/step - loss: 0.1747 - val_loss: 0.1441\n",
      "Epoch 10/25\n",
      "81/81 [==============================] - 10s 120ms/step - loss: 0.1673 - val_loss: 0.1482\n",
      "Epoch 11/25\n",
      "81/81 [==============================] - 10s 119ms/step - loss: 0.1567 - val_loss: 0.1439\n",
      "Epoch 12/25\n",
      "81/81 [==============================] - 10s 119ms/step - loss: 0.1553 - val_loss: 0.1400\n",
      "Epoch 13/25\n",
      "81/81 [==============================] - 10s 118ms/step - loss: 0.1490 - val_loss: 0.1511\n",
      "Epoch 14/25\n",
      "81/81 [==============================] - 10s 119ms/step - loss: 0.1472 - val_loss: 0.1598\n",
      "Epoch 15/25\n",
      "81/81 [==============================] - 10s 118ms/step - loss: 0.1418 - val_loss: 0.1381\n",
      "Epoch 16/25\n",
      "81/81 [==============================] - 10s 118ms/step - loss: 0.1391 - val_loss: 0.1458\n",
      "Epoch 17/25\n",
      "81/81 [==============================] - 10s 119ms/step - loss: 0.1306 - val_loss: 0.1907\n",
      "Epoch 18/25\n",
      "81/81 [==============================] - 10s 118ms/step - loss: 0.1307 - val_loss: 0.1463\n",
      "Epoch 19/25\n",
      "81/81 [==============================] - 10s 119ms/step - loss: 0.1267 - val_loss: 0.1823\n",
      "Epoch 20/25\n",
      "81/81 [==============================] - 10s 118ms/step - loss: 0.1294 - val_loss: 0.1582\n",
      "Epoch 21/25\n",
      "81/81 [==============================] - 9s 117ms/step - loss: 0.1259 - val_loss: 0.1526\n",
      "Epoch 22/25\n",
      "81/81 [==============================] - 10s 118ms/step - loss: 0.1238 - val_loss: 0.1569\n",
      "Epoch 23/25\n",
      "81/81 [==============================] - 9s 117ms/step - loss: 0.1195 - val_loss: 0.1600\n",
      "Epoch 24/25\n",
      "81/81 [==============================] - 9s 116ms/step - loss: 0.1259 - val_loss: 0.1505\n",
      "Epoch 25/25\n",
      "81/81 [==============================] - 10s 117ms/step - loss: 0.1188 - val_loss: 0.1569\n",
      "51/51 [==============================] - 0s 3ms/step\n",
      "\n",
      "\n",
      "R2 score selfie only: 0.5414890019592636\n",
      "MSE score selfie only: 0.16805596506880416\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 19:39:03.883881: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Train the models\n",
    "hist_selfie = selfie_model.fit(\n",
    "    sf_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=25,\n",
    "    batch_size=64,\n",
    ")\n",
    "selfie_model_pred = selfie_model.predict(sf_test)\n",
    "print(f\"\\n\\nR2 score selfie only: {r2_score(y_test, selfie_model_pred)}\")\n",
    "print(f\"MSE score selfie only: {mean_squared_error(y_test, selfie_model_pred)}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "R2 score single: 0.42\n",
      "MSE score single: 0.21\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### DESCRIPTOR INPUT MODEL ####\n",
    "\n",
    "# Base line of the descriptor model\n",
    "scaler = StandardScaler().fit(x_train)\n",
    "estimator = Ridge(alpha=0.055, random_state=42)\n",
    "estimator.fit(scaler.transform(x_train), y_train)\n",
    "est_pred = estimator.predict(scaler.transform(x_test))\n",
    "print(f\"\\n\\nR2 score single: {r2_score(y_test, est_pred):.2f}\")\n",
    "print(f\"MSE score single: {mean_squared_error(y_test, est_pred):.2f}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 11:06:28.721042: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-18 11:06:28.735663: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_10 (Normaliz  (None, 104)               209       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " OUTPUT (Dense)              (None, 1)                 105       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 314 (1.23 KB)\n",
      "Trainable params: 105 (420.00 Byte)\n",
      "Non-trainable params: 209 (840.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Reset the data\n",
    "lec_data = notebook_dataset()\n",
    "\n",
    "# Normalization layer\n",
    "normal_layer = Normalization()\n",
    "normal_layer.adapt(x_train)\n",
    "\n",
    "# Model\n",
    "desc_model = Sequential(\n",
    "    [\n",
    "        Input(shape=(x_train.shape[1],), name=\"DESCRIPTORS\"),\n",
    "        normal_layer,\n",
    "        # tf.keras.layers.Dense(32, activation='relu', name=\"HIDDEN_0\"),\n",
    "        # tf.keras.layers.Dropout(0.3),\n",
    "        # tf.keras.layers.Dense(16, activation='relu', name=\"HIDDEN_1\"),\n",
    "        # tf.keras.layers.Dropout(0.3),\n",
    "        # tf.keras.layers.Dense(8, activation='relu', name=\"HIDDEN_2\"),\n",
    "        # tf.keras.layers.Dropout(0.2),\n",
    "        Dense(1, name=\"OUTPUT\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "desc_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='mean_squared_error',\n",
    ")\n",
    "\n",
    "desc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19/81 [======>.......................] - ETA: 0s - loss: 20.2634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 11:06:32.770263: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 1s 7ms/step - loss: 17.0604 - val_loss: 13.5259\n",
      "Epoch 2/50\n",
      "12/81 [===>..........................] - ETA: 0s - loss: 13.4781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 11:06:33.327675: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 6ms/step - loss: 11.2733 - val_loss: 8.8724\n",
      "Epoch 3/50\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 7.1895 - val_loss: 5.6917\n",
      "Epoch 4/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 4.4280 - val_loss: 3.3730\n",
      "Epoch 5/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 2.6555 - val_loss: 2.0459\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 1.5719 - val_loss: 1.2285\n",
      "Epoch 7/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.8972 - val_loss: 0.6779\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.5462 - val_loss: 0.4335\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.3710 - val_loss: 0.3215\n",
      "Epoch 10/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2856 - val_loss: 0.2540\n",
      "Epoch 11/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2428 - val_loss: 0.2356\n",
      "Epoch 12/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2337 - val_loss: 0.2180\n",
      "Epoch 13/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2265 - val_loss: 0.2330\n",
      "Epoch 14/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2242 - val_loss: 0.2159\n",
      "Epoch 15/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2215 - val_loss: 0.2182\n",
      "Epoch 16/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2249 - val_loss: 0.2138\n",
      "Epoch 17/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2260 - val_loss: 0.2418\n",
      "Epoch 18/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2211 - val_loss: 0.2174\n",
      "Epoch 19/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2222 - val_loss: 0.2145\n",
      "Epoch 20/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2228 - val_loss: 0.2187\n",
      "Epoch 21/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2230 - val_loss: 0.2094\n",
      "Epoch 22/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2219 - val_loss: 0.2166\n",
      "Epoch 23/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2300 - val_loss: 0.2213\n",
      "Epoch 24/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2328 - val_loss: 0.2376\n",
      "Epoch 25/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2335 - val_loss: 0.2235\n",
      "Epoch 26/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2415 - val_loss: 0.2350\n",
      "Epoch 27/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2321 - val_loss: 0.2197\n",
      "Epoch 28/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2246 - val_loss: 0.2675\n",
      "Epoch 29/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2406 - val_loss: 0.2319\n",
      "Epoch 30/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2368 - val_loss: 0.2484\n",
      "Epoch 31/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2276 - val_loss: 0.2312\n",
      "Epoch 32/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2340 - val_loss: 0.2211\n",
      "Epoch 33/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2390 - val_loss: 0.2321\n",
      "Epoch 34/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2393 - val_loss: 0.2703\n",
      "Epoch 35/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2353 - val_loss: 0.2342\n",
      "Epoch 36/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2289 - val_loss: 0.2208\n",
      "Epoch 37/50\n",
      "81/81 [==============================] - 0s 6ms/step - loss: 0.2367 - val_loss: 0.2195\n",
      "Epoch 38/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2384 - val_loss: 0.2371\n",
      "Epoch 39/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2368 - val_loss: 0.2175\n",
      "Epoch 40/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2598 - val_loss: 0.2282\n",
      "Epoch 41/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2392 - val_loss: 0.2218\n",
      "Epoch 42/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2376 - val_loss: 0.2741\n",
      "Epoch 43/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2424 - val_loss: 0.2239\n",
      "Epoch 44/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2415 - val_loss: 0.2361\n",
      "Epoch 45/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2309 - val_loss: 0.2499\n",
      "Epoch 46/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2299 - val_loss: 0.2146\n",
      "Epoch 47/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2381 - val_loss: 0.2427\n",
      "Epoch 48/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2423 - val_loss: 0.2883\n",
      "Epoch 49/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2320 - val_loss: 0.2284\n",
      "Epoch 50/50\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 0.2299 - val_loss: 0.2144\n",
      "51/51 [==============================] - 0s 2ms/step\n",
      "\n",
      "\n",
      "R2 score descriptors only: 0.37853612070324816\n",
      "MSE score descriptors only: 0.2277823485955716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 11:06:54.534466: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Train the models\n",
    "hist_desc = desc_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_split=0.20,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "desc_model_pred = desc_model.predict(x_test)\n",
    "print(f\"\\n\\nR2 score descriptors only: {r2_score(y_test, desc_model_pred)}\")\n",
    "print(f\"MSE score descriptors only: {mean_squared_error(y_test, desc_model_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the models\n",
    "desc_model.save('models/lec_desc_only_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MULTI INPUT MODEL ####\n",
    "\n",
    "# Reset the data\n",
    "lec_data = notebook_dataset()\n",
    "\n",
    "# Now create a multi-input model with the embedded SELFIES and the other features using Functional API\n",
    "selfie_input_layer = Input(shape=(max_len,), dtype=object, name=\"SELFIES\")\n",
    "lookup_layer = StringLookup(**lookup_params)(selfie_input_layer)\n",
    "embed_layer = Embedding(**embed_params)(lookup_layer)\n",
    "embed_flat_layer = Flatten(name=\"SELFIES_FLAT\")(embed_layer)\n",
    "\n",
    "\n",
    "# Create a new input layer for the continuous features\n",
    "descriptors_layer = Input(shape=(x_train.shape[1],), name=\"DESCRIPTORS\")\n",
    "\n",
    "# Create a normalization layer for the continuous features\n",
    "normalized_layer = normal_layer(descriptors_layer)\n",
    "\n",
    "# Concatenate the embedded SELFIES and the continuous features\n",
    "concat_layer = Concatenate()([embed_flat_layer, normalized_layer])\n",
    "\n",
    "# Add the regression layers\n",
    "hidden_layer = Dense(256, activation='relu', name=\"HIDDEN_0\")(concat_layer)\n",
    "dropout_layer = Dropout(0.4)(hidden_layer)\n",
    "output_layer = Dense(1, name=\"OUTPUT\")(dropout_layer)\n",
    "\n",
    "# Create the model\n",
    "multi_input_model = Model(inputs=[selfie_input_layer, descriptors_layer], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "multi_input_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error',\n",
    ")\n",
    "multi_input_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "hist_multi = multi_input_model.fit(\n",
    "    {\"SELFIES\": sf_train, \"DESCRIPTORS\": x_train},\n",
    "    y_train,\n",
    "    validation_split=0.20,\n",
    "    epochs=10,\n",
    "    batch_size=64\n",
    ")\n",
    "multi_input_model_pred = multi_input_model.predict([sf_test, x_test])\n",
    "print(f\"R2 score multi: {r2_score(y_test, multi_input_model_pred)}\")\n",
    "print(f\"RMSE score multi: {mean_squared_error(y_test, multi_input_model_pred)}\")\n",
    "\n",
    "# Save the model\n",
    "multi_input_model.save('models/lec_selfies_multi_model.keras')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
